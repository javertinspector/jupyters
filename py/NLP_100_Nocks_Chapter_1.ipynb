{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 言語処理100本ノック\n",
    "\n",
    "http://www.cl.ecei.tohoku.ac.jp/nlp100/\n",
    "\n",
    "この問題をといていく\n",
    "\n",
    "## 第1章：準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.0 \"stressed\"の反転文字列の取得\n",
    "#### 参考になったURL http://d.hatena.ne.jp/redcat_prog/20111104/1320395840\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "moji = \"stressed\"\n",
    "reveresed = moji[::-1]\n",
    "print(reveresed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.1 「パタトクカシーー」の1,3,5,7文字目を取ってつなげた文字列の取得\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "moji = \"パタトクカシーー\"\n",
    "result = moji[:7:2]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.2 「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」の取得\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "patrolcar = \"パトカー\"\n",
    "taxi      = \"タクシー\"\n",
    "mixedcar  = \"\".join([j for i in zip(patrolcar,taxi) for j in i])\n",
    "print(mixedcar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.3 \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\n",
    "#### \"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "phrases  = sentence.split(\" \")\n",
    "num_alphabets = [len(j) if j.find(',') == -1 and j.find('.') == -1 else len(j)-1 for j in phrases]\n",
    "print(num_alphabets)\n",
    "\n",
    "#内包表記を使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.4 \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "#### という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，\n",
    "#### 取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('H', 1), ('He', 2), ('Li', 3), ('Be', 4), ('B', 5), ('C', 6), ('N', 7), ('O', 8), ('F', 9), ('Ne', 10), ('Na', 11), ('Mi', 12), ('Al', 13), ('Si', 14), ('P', 15), ('S', 16), ('Cl', 17), ('Ar', 18), ('Ki', 19), ('Ca', 20)]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "phrases  = sentence.split(\" \")\n",
    "results  = {phrases[j][0:1] if j == 0 or j == 4 or j == 5 or j == 6 or j == 7 or j == 8 or j == 14 or j == 15 else phrases[j][0:2] : j+1 for j in range(len(phrases))}\n",
    "results  = sorted(results.items(), key=lambda x: x[1])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.5 与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iam\n",
      "aman\n",
      "anNLPer\n",
      "NLPer\n",
      "------\n",
      "Ia\n",
      "am\n",
      "ma\n",
      "an\n",
      "nN\n",
      "NL\n",
      "LP\n",
      "Pe\n",
      "er\n",
      "r\n"
     ]
    }
   ],
   "source": [
    "def n_gram(seq, n, unit=None):\n",
    "    if unit == None:\n",
    "        unit == \"char\"\n",
    "    if unit == \"char\":\n",
    "        seq = \"\".join(seq.split(\" \"))\n",
    "        for i in range(len(seq)):\n",
    "            tmp = \"\"\n",
    "            if i+n <= len(seq):\n",
    "                tmp = seq[i:i+n]\n",
    "            else:\n",
    "                tmp = seq[i:]\n",
    "            print(tmp)\n",
    "    if unit == \"phrase\":\n",
    "        seq = seq.split(\" \")\n",
    "        for i in range(len(seq)):\n",
    "            tmp = \"\"\n",
    "            if i == len(seq):\n",
    "                tmp += seq[i]\n",
    "            else:\n",
    "                for j in range(n):\n",
    "                    if i+j >= 0 and i+j < len(seq):\n",
    "                        tmp += seq[i+j]\n",
    "            print(tmp)\n",
    "            \n",
    "\n",
    "targets = \"I am an NLPer\"\n",
    "n_gram(targets, 2, \"phrase\")\n",
    "print(\"------\")\n",
    "n_gram(targets, 2, \"char\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.6 \"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ. さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ．\n",
    "\n",
    "#### 参考URL:  https://qiita.com/Tocyuki/items/0bc783daab382ef7a0ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is', 'h', 'ph', 'ag', 'ad', 'pa', 'ap', 'se', 'ra', 'e', 'gr', 'di', 'ar'}\n",
      "{'ap', 'pa', 'ra', 'ar'}\n",
      "{'se', 'is', 'e', 'ad', 'di'}\n"
     ]
    }
   ],
   "source": [
    "# 上のアウトプットをリスト型にした。\n",
    "\n",
    "def n_gram(seq, n, unit=None):\n",
    "    results = []\n",
    "    if unit == None:\n",
    "        unit == \"char\"\n",
    "    if unit == \"char\":\n",
    "        seq = \"\".join(seq.split(\" \"))\n",
    "        for i in range(len(seq)):\n",
    "            tmp = \"\"\n",
    "            if i+n <= len(seq):\n",
    "                tmp += seq[i:i+n]\n",
    "            else:\n",
    "                tmp += seq[i:]\n",
    "            results.append(tmp)\n",
    "    if unit == \"phrase\":\n",
    "        seq = seq.split(\" \")\n",
    "        for i in range(len(seq)):\n",
    "            tmp = \"\"\n",
    "            if i == len(seq):\n",
    "                tmp += seq[i]\n",
    "            else:\n",
    "                for j in range(n):\n",
    "                    if i+j >= 0 and i+j < len(seq):\n",
    "                        tmp += seq[i+j]\n",
    "            results.append(tmp)\n",
    "    return results\n",
    "\n",
    "X = set(n_gram(\"paraparaparadise\", 2, \"char\"))\n",
    "Y = set(n_gram(\"paragraph\", 2, \"char\"))\n",
    "\n",
    "wa = X | Y\n",
    "seki = X & Y\n",
    "sa = X - Y\n",
    "\n",
    "print(wa)\n",
    "print(seki)\n",
    "print(sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.7 引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=\"気温\", z=22.4として，実行結果を確認せよ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def outputs(x, y, z):\n",
    "    return str(x) + \"時の\" + str(y) + \"は\" + str(z)\n",
    "\n",
    "res = outputs(12, \"気温\", 22.4)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.8 与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "英小文字ならば(219 - 文字コード)の文字に置換. その他の文字はそのまま出力\n",
    "#### この関数を用い，英語のメッセージを暗号化・復号化せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encrytped: zzzAyByyx\n",
      "decrypted: aaaAbBbbc\n"
     ]
    }
   ],
   "source": [
    "def encrypt(texts):\n",
    "    result =\"\"\n",
    "    for i in texts:\n",
    "        if ord(i) >= 97 and ord(i) <= 122:\n",
    "            result += chr(219 - ord(i))\n",
    "        else:\n",
    "            result += i\n",
    "    return result\n",
    "def decrypt(texts):\n",
    "    result = \"\"\n",
    "    for i in texts:\n",
    "        if ord(i) >= 97 and ord(i) <= 122:\n",
    "            result += chr(219 - ord(i))\n",
    "        else:\n",
    "            result += i\n",
    "    return result\n",
    "\n",
    "\n",
    "text = \"aaaAbBbbc\"\n",
    "\n",
    "enc  = encrypt(text)\n",
    "print(\"encrytped: \" + enc)\n",
    "dec  = decrypt(enc)\n",
    "print(\"decrypted: \" + dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### No.9 スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def randomize(phrases):\n",
    "    result = \"\"\n",
    "    for i in range(len(phrases))\n",
    "        result = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
